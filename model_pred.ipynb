{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn #network 函式\n",
    "import torch.nn.functional as F #一些方法\n",
    "import torch.optim as optim #優化方法\n",
    "from torchvision import datasets, transforms #提供資料集 演算法\n",
    "import matplotlib.pyplot as plt #圖表\n",
    "from PIL import Image, ImageFilter , ImageOps\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    \"\"\"在影像中加入高斯雜訊\n",
    "    \n",
    "    參數:\n",
    "        mean (float): 高斯雜訊的均值\n",
    "        std  (float): 高斯雜訊的標準差\n",
    "        p    (float): 有多大機率對影像做此增強\n",
    "    \"\"\"\n",
    "    def __init__(self, mean=0., std=1., p=0.5):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # 先以機率 p 判斷要不要施加雜訊\n",
    "        if random.random() < self.p:\n",
    "            # (1) 轉成 Tensor (若原本還是 PIL Image)\n",
    "            if isinstance(img, Image.Image):\n",
    "                img = transforms.ToTensor()(img)  # shape: [C, H, W]\n",
    "\n",
    "            # (2) 加入高斯雜訊\n",
    "            noise = torch.randn(img.size()) * self.std + self.mean\n",
    "            img = img + noise\n",
    "\n",
    "            # (3) clip 到 [0,1] 區間，確保像素值合理 (可依需求調整)\n",
    "            img = torch.clamp(img, 0., 1.)\n",
    "\n",
    "            # (4) 若需要再轉回 PIL 就執行\n",
    "            img = transforms.ToPILImage()(img)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}(mean={self.mean}, std={self.std}, p={self.p})\"\n",
    "\n",
    "    \n",
    "class Addblur(object):\n",
    "    def __init__(self, p=0.5,blur=\"normal\"):\n",
    "        #         self.density = density\n",
    "        self.p = p\n",
    "        self.blur= blur\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.uniform(0, 1) < self.p:  # 概率的判断\n",
    "       \t\t#標準模糊\n",
    "            if self.blur== \"normal\":\n",
    "                img = img.filter(ImageFilter.BLUR)\n",
    "                return img\n",
    "            #高斯模糊\n",
    "            if self.blur== \"Gaussian\":\n",
    "                img = img.filter(ImageFilter.GaussianBlur)\n",
    "                return img\n",
    "            #均值模糊\n",
    "            if self.blur== \"mean\":\n",
    "                img = img.filter(ImageFilter.BoxBlur)\n",
    "                return img\n",
    "        else:\n",
    "            return img\n",
    "        \n",
    "class InvertColors(object):\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.p:# 若隨機數小於 p 則反轉顏色\n",
    "            img = ImageOps.invert(img) # 若是灰階或 RGB，直接反轉\n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}(p={self.p})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'kanaA', 1: 'kanaBA', 2: 'kanaCHI', 3: 'kanaDA', 4: 'kanaE', 5: 'kanaFU', 6: 'kanaHA', 7: 'kanaHE', 8: 'kanaHI', 9: 'kanaHO', 10: 'kanaI', 11: 'kanaJI', 12: 'kanaKA', 13: 'kanaKE', 14: 'kanaKI', 15: 'kanaKO', 16: 'kanaKU', 17: 'kanaMA', 18: 'kanaME', 19: 'kanaMI', 20: 'kanaMO', 21: 'kanaMU', 22: 'kanaN', 23: 'kanaNA', 24: 'kanaNE', 25: 'kanaNI', 26: 'kanaNO', 27: 'kanaNU', 28: 'kanaO', 29: 'kanaPI', 30: 'kanaRA', 31: 'kanaRE', 32: 'kanaRI', 33: 'kanaRO', 34: 'kanaRU', 35: 'kanaSA', 36: 'kanaSE', 37: 'kanaSHI', 38: 'kanaSO', 39: 'kanaSU', 40: 'kanaTA', 41: 'kanaTE', 42: 'kanaTO', 43: 'kanaTSU', 44: 'kanaU', 45: 'kanaWA', 46: 'kanaWO', 47: 'kanaYA', 48: 'kanaYO', 49: 'kanaYU'}\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((64,64)), #\n",
    "    transforms.ToTensor(),  # shape H，W，C —> C，H，W\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) # 將資料壓縮至一個範圍，例如：-1,1，這樣跑的效率會比較高\n",
    "])\n",
    "transformAddNoices = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((64,64)), #\n",
    "    AddGaussianNoise(mean=0., std=0.5, p=1),\n",
    "    transforms.ToTensor(),  # shape H，W，C —> C，H，W\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) # 將資料壓縮至一個範圍，例如：-1,1，這樣跑的效率會比較高\n",
    "])\n",
    "transformAddBlur = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((64,64)), #\n",
    "    Addblur(p=1,blur=\"normal\"),\n",
    "    transforms.ToTensor(),  # shape H，W，C —> C，H，W\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) # 將資料壓縮至一個範圍，例如：-1,1，這樣跑的效率會比較高\n",
    "])\n",
    "transformColoeRev = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1), \n",
    "    transforms.Resize((64,64)), #\n",
    "    InvertColors(p=1), \n",
    "    transforms.ToTensor(),  # shape H，W，C —> C，H，W\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) # 將資料壓縮至一個範圍，例如：-1,1，這樣跑的效率會比較高\n",
    "])\n",
    "hahtransform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((64,64)), #\n",
    "    InvertColors(p=1), \n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root='./hiragana-dataset-master/process') #使用ImageFolder加載資料集\n",
    "label_dict = dataset.class_to_idx #生出 label:index 的字典\n",
    "reverse_label_dict = {v: k for k, v in label_dict.items()} #原始字典 label_dict 的key值對交換後生成一個新的字典 reverse_label_dict\n",
    "print(reverse_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kanaRO\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABAAEABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APf6KKKKKKKKK888QeJvHVp4kew0fwxHc2fGy5kkwD9fSqouPixqFySlrpOmxKvR28zcaydcvviP4SsbrUdR8Q6MbcnKCVMHOPuqK3vhT4i8V+KNOm1LXooEtHwLYom0t6n6V6LRRRSVwviz4k2ui3w0bSraTU9bkGI7eHkKe241zmlfDnXPFd/DrHj29Mnltui05P8AVqPQ161b28VrAkEEaxxRgKqKMACpKKKytc8SaR4dtGudUvordAOjNyfoK8p1jxx4i8V3q2mkXFvoeizDi/unCvKnfaO1dT4PXwN4fsAbTVrCe63HzbuWUGR2HBOTzWzefEbwjYz+TPrtoHxnCvu/lWZB8YPBs9w0Q1F0UEjzniIQ/wDAq7Ow1C01O0S6sriOeB/uvG2Qas0yUSGFxEQJNp2k9M9q8Q1X4LeIvFuuz33iLxChUkiPykJwOwAPQVv6T8CPDFksZvpbu/ZMYEsmFBHoB2rW1D4OeC9QnSV9M8oqoULC5UYHtV/Tvhl4Q0x1eDRbdnXOGkG4/rWnqGhaBFotxDc6ZaCyVGd08sAYxXG/BaGL/hH9SurSOWGxnvpDbQscqqDjIr02iiiiql/qljpdu1xfXcNvEoyWkcCvJ9e8T3vxNvl8N+FllGkM2L7UCuFK55VTXqukaXb6NpNtp1qirDAgQADGfer1FFFB6V5td/B3TdX1ifUNb1S/vhJIziBpNqKD0GK7vSdHsNDsEstOto7e3ToiDFXqKKKKKKKKK//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAAAAACPAi4CAAAFmklEQVR4Ae1WW28TRxSe2fV1YzsNLKR27LghJDRNQlBS0gAFRFpEhVChoLZAX/uAxC+o+lPaiodIrVRVqtqqiKZpuSUQaHNpUigkpLk0FxxCTGISO453pufMrje7joOl8tAXRvZ65uw533znm5kzppw8X5OeL5yQFwA5GuCKcC6eqC301gbCoI+xazZqW0ZGKcTBFxonog8/opeNsA3AmLMKBh6iUiRDBQUdEcc6bBYMf+0M0CIyoBCvrTIYpkYXykIyviCyEwga/IQBHzYAmBCmXF7WMeYG5sBhoTtWX+sW/lubI5JBRozFw7HWFT1O5roGkhJSjfUBgOyajw+362GVXPXlEiA2ACSYGfz8dlqSYaqMpgYdvujiJLBcmZjmjpBHT8U2pw2Ao6aS20XdlRUOyjx19W5XIJ3gdGX8qzmp9kS9F1LExbE0GwAK4tj5cUtKqauSKZECfnAGY7Lv3gwLHv8wvD4ed4ulaYwzbSk+H09CBxqHJ2dLVz4KeoPnb6XBE0z2ZgcQ/owhjnBDmNVHP59RveFzPQLUHg0jWwqcAl/QGRYhq7aWGL5+9cZS05Gj9c41q0UDTDuncS5WUailjXZ09MWcladPlTnt4mWD8gCI7YpyweqNff3NiGN7c+vrEWeu/AaCLQUTFWI5Zcux3ss/zQSaPtgf9LL1THXvfAzEgWT06Y1L3X9L0QOtTZvxaGzAIB8ACAgMFi9/1i3VHWzZqbrEZsgvgf0wZVMA/qnZmxd65OrzbxU7IBL4bxBvPwv6WUbXdP/FznsN+ypbVEEHTqnIK08a61IAH5ac+vPbK4Hdp/YoblnkjijiY3I0O7ZVQKacLE39/mvvP5tOnK4oguqgFzncYrjLoOXkYgNApnS268qNB+m6o0eqPOiO5OHD1pcSnYQNAGpeZu5i20AqWHvynRKnHg854d5kGUaoBO6IaGl2DdLzQ9fbh7To+wer3asel65dKom18eGdBHFt2+Z2K/Y6bAAIiTJP/rp280G0wePfHSZD49UVXIKs2fDgEmF0sjdO3TU7fDW7Qoq1LGQZwM6dv9t9rf/xlpNvJnrilE3GwkGRPJ8cScoyz2S2bCHxBVbe+N4BhUlmIiYAlI0vemcz3F9evDyRkD2KmpxahQLngPJIg1UKVXbWssHOvph8/NPtwCyrRBZAm+78vj2O3AhxbXKV7NoRHv8hRohS5g9tptEmH3X4/Twx0vXLbfWTY8VrAMYqsOnvvrz7lEgSKQoVqXuDvrqQ69FrTxj1lBaV+ikoB4JyUrLrlUrt/nTacgIMgMzgj/dXFH+VKoVaSpXoS9RBqbcM1KeSvtthgyCCHCh2RxoDYkfpa2kASOqhyFxZpDlMvCpeQ0hRkkVGGAgJC9UYWez+oyboNiWEKq7jyPUVj+dLi/3ZVygRFoHsrxjBZtZGOmOvotGEMACIx7uJyVALNzgyYhrKSGbsnhz1CXRhMq93iJOckCOAI/4GTWITvz0pb91qfW3uS/3AgjoWgayOor/Q0a60NoBI4m+DMBkAQB3PLd7/66LWDKk7l6b2nY3q8hhmA0DwFtNvCMFJqqet37+jwoW3mYlqpgAWmF9nYb6Fju6Kz5XBtov02P4idLSErbvscgzigoU7MrN4+1zQf7xrOed6zS6jdVJr31hXLTnRfbkjtedMjSdnlcTpsUbk9qEawd+myf6OWzOeprOHS1BBayvIgGip2Zmha72jmeoTBxoC9mhAKsSAJ/qGBwceTq0odaffDcLfFnMPGzQKMdDGLlxdWHSXqG8c3vsyap9LoRDAyuhwKuzZ1hyuj3gta7emQiEAR/nbUqNPjShw0vK2AhrARTFPS2AW9MtlLwALAOiawSnFz38CMFTH2pQ3vuAy5s3batxAGqvLs/svAMyq/GyhnvX2/xfxX707tLo+4urAAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_path = Path('./models/model_try.pt') # TODO: adjust path\n",
    "assert model_path.exists() is True\n",
    "image_path = Path('./hiragana-dataset-master/process/kanaRO/kanaRO19.jpg') # TODO: adjust path\n",
    "assert image_path.exists() is True\n",
    "\n",
    "model = torch.jit.load(model_path).to(device)\n",
    "test_image = Image.open(image_path)\n",
    "trans_image = transformColoeRev(test_image).to(device)\n",
    "hahtrans_image = hahtransform(test_image)\n",
    "pred = model(trans_image.unsqueeze(0))\n",
    "_, pred_label = pred.max(1)\n",
    "print(reverse_label_dict.get(int(pred_label)))\n",
    "hahtrans_image "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mainEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
