{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn #network 函式\n",
    "import torch.nn.functional as F #一些方法\n",
    "import torch.optim as optim #優化方法\n",
    "from torchvision import datasets, transforms #提供資料集 演算法\n",
    "import matplotlib.pyplot as plt #圖表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 資料前處理 ###\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "data_path = os.listdir('C:/Users/bymin/OneDrive/桌面/pytorch/hiragana-dataset-master/hiragana_images') #定義data_path\n",
    "for i in data_path: #對data_path裡所有資料\n",
    "    label = i.replace(\".jpg\",\"\").strip('0123456789') #把label掐頭去尾\n",
    "    if not os.path.exists('C:/Users/bymin/OneDrive/桌面/pytorch/hiragana-dataset-master/process'): #製作 process 資料夾，存放資料分類\n",
    "        os.mkdir('C:/Users/bymin/OneDrive/桌面/pytorch/hiragana-dataset-master/process')\n",
    "        \n",
    "    data = 'C:/Users/bymin/OneDrive/桌面/pytorch/hiragana-dataset-master/process/'+ label\n",
    "    if not os.path.exists(data): #找這label的資料夾是否存在 否則新增資料夾\n",
    "        os.mkdir(data)\n",
    "        \n",
    "    data_src = 'C:/Users/bymin/OneDrive/桌面/pytorch/hiragana-dataset-master/hiragana_images/' + i \n",
    "    data_copy =  data + \"/\" + i\n",
    "    shutil.copy(data_src, data_copy) #複製資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu124\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "##超參數\n",
    "batch_size = 32 #批次大小\n",
    "lr = 0.001 #學習率\n",
    "num_epochs = 10 #代數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'kanaA', 1: 'kanaBA', 2: 'kanaCHI', 3: 'kanaDA', 4: 'kanaE', 5: 'kanaFU', 6: 'kanaHA', 7: 'kanaHE', 8: 'kanaHI', 9: 'kanaHO', 10: 'kanaI', 11: 'kanaJI', 12: 'kanaKA', 13: 'kanaKE', 14: 'kanaKI', 15: 'kanaKO', 16: 'kanaKU', 17: 'kanaMA', 18: 'kanaME', 19: 'kanaMI', 20: 'kanaMO', 21: 'kanaMU', 22: 'kanaN', 23: 'kanaNA', 24: 'kanaNE', 25: 'kanaNI', 26: 'kanaNO', 27: 'kanaNU', 28: 'kanaO', 29: 'kanaPI', 30: 'kanaRA', 31: 'kanaRE', 32: 'kanaRI', 33: 'kanaRO', 34: 'kanaRU', 35: 'kanaSA', 36: 'kanaSE', 37: 'kanaSHI', 38: 'kanaSO', 39: 'kanaSU', 40: 'kanaTA', 41: 'kanaTE', 42: 'kanaTO', 43: 'kanaTSU', 44: 'kanaU', 45: 'kanaWA', 46: 'kanaWO', 47: 'kanaYA', 48: 'kanaYO', 49: 'kanaYU'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1), #因為資料輸入後頻道為3 所以這邊做灰度 \n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    \n",
    "    transforms.ToTensor(),  # shape H，W，C —> C，H，W\n",
    "    transforms.Resize((64,64)), #\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) # 將資料壓縮至一個範圍，例如：-1,1，這樣跑的效率會比較高\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root='C:/Users/bymin/OneDrive/桌面/pytorch/hiragana-dataset-master/process', transform=transform) #使用ImageFolder加載資料集\n",
    "train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42) #sklearn分割資料集 train:test 8:2 random_state=42：設定隨機種子，保證每次分割的結果一致。\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True) #shuffle=True 隨機打散資料集\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "label_dict = dataset.class_to_idx #生出 label:index 的字典\n",
    "reverse_label_dict = {v: k for k, v in label_dict.items()} #原始字典 label_dict 的key值對交換後生成一個新的字典 reverse_label_dict\n",
    "print(reverse_label_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cnn(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=9216, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=50, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Cnn, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=0)\n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=0)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(256*6*6, 512) #第一層全連接層 輸入256*8*8 輸出512\n",
    "        self.fc2 = nn.Linear(512, 50) #第二層全連接層 輸入512 輸出50個類別\n",
    "        \n",
    "    def forward(self, x): #\n",
    "        x = self.pool(F.relu(self.conv1(x))) # 卷積 -> sigmoid -> 池化 84 -> conv1 -> 82 -> pool -> 41\n",
    "        x = self.pool(F.relu(self.conv2(x))) # 41 -> conv2 -> 39 -> pool -> 19\n",
    "        x = self.pool(F.relu(self.conv3(x))) # 19 -> conv3 -> 17 -> pool -> 8\n",
    "        # print(x.shape) #此時x.shape = (batch_size, 256, 8, 8)\n",
    "        x = x.view(-1, 256*6*6) #圖像攤平成 (batch_size, 256個維度*(8*8)個像素) -1讓 PyTorch 自動推斷 batch 大小 一個向量\n",
    "        x = F.relu(self.fc1(x)) #將x 丟進fc1後 應用relu激活函數\n",
    "        x = self.fc2(x) #將x丟進fc2\n",
    "        \n",
    "        return x #這邊輸出x不做softmax的訓練結果較好\n",
    "    \n",
    "model = Cnn()\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "\n",
    "## 優化器\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.Adagrad(model.parameters(), lr=lr)\n",
    "\n",
    "# criterion = nn.MSELoss().to(device)\n",
    "# criterion = nn.L1Loss().to(device)\n",
    "# criterion = nn.BCELoss().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)  #交叉商"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/10] loss: 2.7641214418411253, acc: 0.3175\n",
      "Epoch[2/10] loss: 0.46603880643844603, acc: 0.87\n",
      "Epoch[3/10] loss: 0.12608944365754723, acc: 0.96\n",
      "Epoch[4/10] loss: 0.063017196059227, acc: 0.98875\n",
      "Epoch[5/10] loss: 0.0068777625495567915, acc: 0.9975\n",
      "Epoch[6/10] loss: 0.0018616850400576368, acc: 1.0\n",
      "Epoch[7/10] loss: 0.0005485209211474284, acc: 1.0\n",
      "Epoch[8/10] loss: 0.00015027321569505148, acc: 1.0\n",
      "Epoch[9/10] loss: 7.456379840732552e-05, acc: 1.0\n",
      "Epoch[10/10] loss: 6.0981799651926846e-05, acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "def accuracy(pred: torch.Tensor, label: torch.Tensor):\n",
    "  # pred.max(1) 會在第1軸(也就是 class 的那一軸)找出最大值\n",
    "  # 此函式會回傳(最大值, 最大值所在索引) 這兩個tensor\n",
    "  # 其中 pred_label = 最大值所在的索引，也就代表模型預測的類別\n",
    "  _, pred_label = pred.max(1)\n",
    "  num_correct = (pred_label == label).sum().item() \n",
    "  acc = num_correct / label.shape[0] # 準確度 = 正確預測數量 / 總樣本數\n",
    "  return acc\n",
    "\n",
    "\n",
    "metric = {'loss': [], 'acc': []}\n",
    "for i_epoch in range(num_epochs):\n",
    "  train_loss = [] #宣告train的loss\n",
    "  train_acc = [] #宣告train的acc\n",
    "  model.train(mode=True) #模型轉為訓練模式\n",
    "  for i_batch, (image, label) in enumerate(train_loader): #迭代每個batch \n",
    "    image = image.to(device) #圖片丟進gpu\n",
    "    label = label.to(device) #label丟進gpu\n",
    "\n",
    "    pred = model.forward(image) #預測pred 將圖片丟進模型 模型輸出的(未經 softmax) 形狀(batch_size, num_classes)\n",
    "    loss = criterion(pred, label) #使用 CrossEntropyLoss，計算此次 batch 的 loss，將 pred 與 label 做比較\n",
    "\n",
    "    optimizer.zero_grad()  #上一輪的梯度歸零\n",
    "    loss.backward() # 反向傳播 計算梯度\n",
    "    optimizer.step() #optimizer進行參數更新\n",
    "\n",
    "    train_loss += [loss.item()] #將該 batch 的損失記錄到 train_loss 清單\n",
    "    train_acc += [accuracy(pred, label)] #計算該 batch 的準確度，並記錄到 train_acc 清單\n",
    "  metric['loss'] += [sum(train_loss)/ len(train_loader)] #統計當前 epoch 所有 batch 的平均 loss\n",
    "  metric['acc'] += [sum(train_acc)/ len(train_loader)] #統計當前 epoch 所有 batch 的平均 acc\n",
    "  print(f'Epoch[{i_epoch+1}/{num_epochs}] loss: {metric[\"loss\"][-1]}, acc: {metric[\"acc\"][-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correct: 193\n",
      "Total samples: 200\n",
      "Test Accuracy: 0.965\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for image, label in test_loader:\n",
    "      image = image.to(device)\n",
    "      label = label.to(device)\n",
    "      pred = model.forward(image)\n",
    "      _, pred_label = pred.max(1)\n",
    "      total_correct += (pred_label == label).sum().item()\n",
    "      total_samples += label.size(0)\n",
    "\n",
    "\n",
    "print(f'Total correct: {total_correct}')\n",
    "print(f'Total samples: {total_samples}')\n",
    "test_acc = total_correct / total_samples\n",
    "print(f'Test Accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "model_path = Path('./models/model.pt') #模型儲存位置/檔名\n",
    "model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "torch.jit.script(model).save(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mainEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
